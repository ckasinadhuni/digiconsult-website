#!/usr/bin/env python3

import json
import requests
from datetime import datetime

# Load config
with open('config.json', 'r') as f:
    config = json.load(f)

headers = {
    "X-N8N-API-KEY": config["api_key"],
    "Content-Type": "application/json"
}

# Create a properly configured single agent workflow
corrected_workflow = {
    "name": f"‚úÖ CORRECTED AI Agent - {datetime.now().strftime('%H:%M:%S')}",
    "nodes": [
        {
            "parameters": {},
            "id": "trigger",
            "name": "Manual Trigger",
            "type": "@n8n/n8n-nodes-base.manualTrigger",
            "typeVersion": 1,
            "position": [240, 300]
        },
        {
            "parameters": {
                "agent": "conversationalAgent",
                "promptType": "define",
                "text": "{{ $json.input || $json.message?.text || 'Hello! How can I help you today?' }}",
                "options": {
                    "systemMessage": "You are a context-aware AI assistant with the following capabilities:\n- Expert analysis and problem-solving\n- Memory of conversation context\n- Access to tools for calculations and web search\n\nProvide helpful, structured responses using this framework:\n1. Context Analysis: Brief assessment\n2. Reasoning: Your thought process\n3. Response: Direct answer or action\n4. Next Steps: Suggested follow-ups",
                    "maxTokens": 4000,
                    "temperature": 0.7
                }
            },
            "id": "ai-agent",
            "name": "Context-Aware AI Agent",
            "type": "@n8n/n8n-nodes-langchain.agent",
            "typeVersion": 1.4,
            "position": [480, 300]
        },
        {
            "parameters": {
                "model": "mistral:7b",
                "options": {
                    "baseURL": config["local_services"]["ollama"],
                    "temperature": 0.7,
                    "maxTokens": 2000
                }
            },
            "id": "ollama-model",
            "name": "Ollama Language Model",
            "type": "@n8n/n8n-nodes-langchain.chatOllama",
            "typeVersion": 1.2,
            "position": [480, 480]
        },
        {
            "parameters": {
                "windowSize": 10,
                "returnMessages": True
            },
            "id": "memory",
            "name": "Conversation Memory",
            "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
            "typeVersion": 1.2,
            "position": [720, 300]
        },
        {
            "parameters": {},
            "id": "web-tool",
            "name": "Web Search Tool",
            "type": "@n8n/n8n-nodes-langchain.toolHttpRequest", 
            "typeVersion": 1.2,
            "position": [720, 180]
        },
        {
            "parameters": {},
            "id": "calc-tool",
            "name": "Calculator Tool",
            "type": "@n8n/n8n-nodes-langchain.toolCalculator",
            "typeVersion": 1.2,
            "position": [720, 420]
        }
    ],
    "connections": {
        "Manual Trigger": {
            "main": [[{"node": "Context-Aware AI Agent", "type": "main", "index": 0}]]
        },
        "Ollama Language Model": {
            "ai_languageModel": [[{"node": "Context-Aware AI Agent", "type": "ai_languageModel", "index": 0}]]
        },
        "Conversation Memory": {
            "ai_memory": [[{"node": "Context-Aware AI Agent", "type": "ai_memory", "index": 0}]]
        },
        "Web Search Tool": {
            "ai_tool": [[{"node": "Context-Aware AI Agent", "type": "ai_tool", "index": 0}]]
        },
        "Calculator Tool": {
            "ai_tool": [[{"node": "Context-Aware AI Agent", "type": "ai_tool", "index": 1}]]
        }
    },
    "settings": {}
}

print("üîÑ Deploying corrected AI Agent workflow...")

try:
    response = requests.post(
        f"{config['base_url']}/api/v1/workflows",
        headers=headers,
        json=corrected_workflow,
        timeout=30
    )
    
    if response.status_code in [200, 201]:
        workflow_info = response.json()
        workflow_id = workflow_info.get('id')
        print(f"‚úÖ CORRECTED workflow deployed! ID: {workflow_id}")
        print(f"üåê View: {config['base_url']}/workflow/{workflow_id}")
        print(f"üìã Test: Click 'Execute Workflow' in n8n UI")
        print("\nüîß Key fixes applied:")
        print("  ‚úÖ Proper LangChain connections (ai_languageModel, ai_memory, ai_tool)")
        print("  ‚úÖ Ollama model connected to agent")
        print("  ‚úÖ Memory properly configured")
        print("  ‚úÖ Tools connected with correct connection types")
        print("  ‚úÖ No empty parameter objects")
        
    else:
        print(f"‚ùå Failed: {response.status_code}")
        print(f"Response: {response.text}")
        
except Exception as e:
    print(f"‚ùå Error: {e}")